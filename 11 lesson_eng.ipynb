{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "905c66ce-17ac-44e1-b107-8b103790a5cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Introduction to Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3bd572-352d-456f-8344-d04a20a5ec9a",
   "metadata": {},
   "source": [
    "Machine learning is a class of artificial intelligence methods, the characteristic feature of which is not the direct solution of a problem, but learning through the application of solutions to many similar problems. To build such methods, the tools of mathematical statistics, numerical methods, mathematical analysis, optimization methods, probability theory, graph theory, various techniques for working with data in digital form are used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faccce6f-9763-4059-9287-136aea55545b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Statement of the business problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154fe83a-0c65-41f6-ba91-9f5e9e048b55",
   "metadata": {},
   "source": [
    "Understanding the problem correctly is half the battle. We will deal with the conditions and think about how we can solve it.\n",
    "\n",
    "Imagine you are working in an online real estate service. Without resorting to the services of agents, the owners place ads, and buyers respond to them. If the transaction is successful, your service takes a commission."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1ca9aa-e390-413a-b3dd-a5d16eaf51d8",
   "metadata": {},
   "source": [
    "To solve the problem, together with experts, you can manually write down the rules that determine the cost.\n",
    "For example:\n",
    "- multiply the area of the apartment by the average cost per square meter in the city;\n",
    "- reduce the cost by 20% if the repair is more than three years old;\n",
    "- increase the price by 30% if the metro is near the house.\n",
    "\n",
    "\n",
    "There can be any number of rules.\n",
    "But it's not that simple. An “expert algorithm” can become your competitive advantage or a useless feature that does not pay off the considerable time and financial costs. In addition, the rules are difficult to scale (enter other markets and regions), and over time they may lose relevance.\n",
    "\n",
    "Machine learning will help to correct the shortcomings of expert rules and solve this problem in a different way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9ab82d-710b-478e-a15f-5685af841eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "warnings.simplefilter(action='ignore', category=SettingWithCopyWarning)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5629fb85-6a19-4238-afcd-b91e1a81421c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/train_data.csv')\n",
    "\n",
    "display(df.shape)\n",
    "display(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5faefd2b-9f7b-40f6-828e-dfa2c1fa5b7d",
   "metadata": {},
   "source": [
    "In data analysis, rows were called observations and columns were called variables.\n",
    "In machine learning, we write objects in rows, and features in columns.\n",
    "\n",
    "The sign to be predicted is the target one: in our problem, this is last_price."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8340e10-2a8a-4d02-8b82-4dd96ebae6bd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Learning with a teacher(supervised)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e41840f-74f2-46b5-9946-7132afa66a69",
   "metadata": {},
   "source": [
    "Machine learning tasks are different. We choose the one that will help develop the desired algorithm.\n",
    "\n",
    "You have a training dataset and a target feature that you need to predict for the rest of the features - the price of the sale of housing. Such tasks belong to the class of \"supervised learning\". The “teacher” poses questions (features) and indicates answers (target feature). And it doesn't explain anything."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b7432b-e04f-4155-86ed-8154c85ebf7e",
   "metadata": {},
   "source": [
    "Recall that all variables and features are of two types: categorical and quantitative. The target feature is no exception.\n",
    "\n",
    "- If the target feature is categorical, then the classification problem is solved (for example, identify an animal in the image).\n",
    "- When there are only two categories - for example, whether the client will return to the online store or not - we are talking about a binary classification.\n",
    "- Is the target trait quantitative? This is a regression task - according to the data, the relationship between variables is restored. This way you can predict the number of news reposts or the sales volume of an online store for the next month."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c51c5dc-6b8f-4977-8143-cd4bc02ace88",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Classification and regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7765628-7a24-4774-a181-4b047d4eb5ef",
   "metadata": {},
   "source": [
    "The cost of selling an apartment is a quantitative target sign. It turns out that we are faced with the task of regression. Getting acquainted with machine learning using her example is inconvenient: the calculations will be too cumbersome due to the many possible answers (any number).\n",
    "\n",
    "It is easier when there are only two options, as in binary classification. Therefore, we first break down all prices into “high” and “low” and predict which class the housing belongs to. And then back to regression.\n",
    "\n",
    "\n",
    "How to determine high and low prices?\n",
    "Let's find the median of prices (it's right in the middle)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2869dfe1-56b0-4b8a-94c8-97ef5d74bed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "median = df['last_price'].median()\n",
    "print(df['last_price'].median()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6faac06f-6870-4263-8340-34de1339a462",
   "metadata": {},
   "source": [
    "After UAH 1,159,000 - high prices, to - low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15702020-1410-4bfe-b756-829e980e854e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['last_price'] > median, 'price_class'] = 1\n",
    "df.loc[df['last_price'] <= median, 'price_class'] = 0\n",
    "\n",
    "features = df.drop(['last_price', 'price_class'], axis=1)\n",
    "target = df['price_class']\n",
    "\n",
    "print(features.shape)\n",
    "print(target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc268e8e-930d-4fc3-97c1-4a72e652657e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Models and algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fdcf13-ccbb-4b89-a703-0b00a1dba786",
   "metadata": {},
   "source": [
    "To make predictions, you need to understand the relationship between features and responses. What does an analyst do? He proposes how these relationships work. And based on it makes predictions.\n",
    "\n",
    "If they match reality, then the assumption is correct. This approach is called modeling, and the assumptions and prediction methods themselves are called machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae1918f-82fe-4dd5-a243-882eaf07c506",
   "metadata": {},
   "source": [
    "Consider one popular model, the decision tree. It can describe the process of making a decision in almost any situation. For example, will Oleksandr go on vacation to Rome:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933d7359-14f8-4868-9d52-9be9b0e34ede",
   "metadata": {},
   "source": [
    "<img src=\"./pict/1.jpg\"  \n",
    "  width=\"1000\"\n",
    "/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa0c6d3-e625-4cc4-87c1-53f6597458a6",
   "metadata": {},
   "source": [
    "In our problem, we will put forward the following assumption: the decision tree determines the price of the apartment.\n",
    "\n",
    "Which of the whole set of trees? To find the one, you need to train the model: choose a decision tree that best suits our training set. Learning algorithms are responsible for this, and their result is called a trained model. From data scientists, you may hear \"model\" instead of \"trained model\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851299f8-bd1f-42cc-85eb-cff4da8022c5",
   "metadata": {},
   "source": [
    "After training, the model is ready to predict: receive new objects (features) as input and give answers (target feature). No more algorithms and training dataset needed.\n",
    "\n",
    "It is important to remember that the process of machine learning is divided into two stages - training the model and the operation of this model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826a893b-7d21-4b6a-bf7d-74f25fea1f8b",
   "metadata": {},
   "source": [
    "<img src=\"./pict/2.png\"  \n",
    "  width=\"640\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37286d2d-657b-4836-8fbd-05bcbb3db2c3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# scikit-learn library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc11576b-224c-4761-b441-1a914acf6826",
   "metadata": {},
   "source": [
    "Learning algorithms are often more complex than the model itself. Therefore, imagine them as black boxes. The main thing is to understand what exactly to put in the box and how to work with what it gives out.\n",
    "\n",
    "Many algorithms are already available in the Python libraries. scikit-learn, or sklearn \"scientific kit for learning\".\n",
    "There are many data tools and models in sklearn, so they are divided into subsections.\n",
    "\n",
    "The tree module contains the decision tree.\n",
    "Each model in sklearn has a separate data structure. DecisionTreeClassifier is a data structure for decision tree classification. Import it from the library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b37af19-1394-4cc5-bc29-7a9464f5f04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405419ce-6341-4385-acef-9d419f253a32",
   "metadata": {},
   "source": [
    "Then we create an object of this data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32b567d-170c-40f0-8025-19ca5d54e659",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483c089c-fe3f-4c40-b372-12efd3e31330",
   "metadata": {},
   "source": [
    "The model variable will store the model. Our model is not yet predictive. In order for it to learn, you need to run the learning algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bd3985-7897-4521-b021-8152e11490db",
   "metadata": {},
   "source": [
    "Let's start by training the model. We saved the training dataset in the features and target variables. To start training, call the fit() method and pass it data as a parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc8cbdd-d393-47d8-ad67-907911ad759e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(features, target) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cba9ef5-9250-4eb8-bcf1-524397dca83c",
   "metadata": {},
   "source": [
    "Now the model variable contains a full-fledged model. To predict the answers, you need to call the predict() method and pass it a table with the features of new objects. Let's create new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d175bd1a-feca-4ef6-ba40-51ed6178247b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features = pd.DataFrame(\n",
    "    [[None, None, 2.8, 25, None, 25, 0, 0, 0, None, 0, 30706.0, 7877.0],\n",
    "     [None, None, 2.75, 25, None, 25, 0, 0, 0, None, 0, 36421.0, 9176.0]],\n",
    "    columns=features.columns)\n",
    "\n",
    "new_features.loc[0, 'total_area'] = 900.0\n",
    "new_features.loc[0, 'rooms'] = 12\n",
    "new_features.loc[0, 'living_area'] = 409.7\n",
    "new_features.loc[0, 'kitchen_area'] = 112.0\n",
    "\n",
    "new_features.loc[1, 'total_area'] = 109.0\n",
    "new_features.loc[1, 'rooms'] = 2\n",
    "new_features.loc[1, 'living_area'] = 32.0\n",
    "new_features.loc[1, 'kitchen_area'] = 40.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9177a27-c3c4-4080-b08d-0a0d2df68de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3249a4f1-5fab-436f-94c2-47cb5abf069d",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = model.predict(new_features) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db050df0-f065-429e-a8d0-e325e3ebfedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(answers.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58955c0-4c51-4323-a6ec-f5571209fc72",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Show models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b88562-2029-4768-abc6-b97426b037ad",
   "metadata": {},
   "source": [
    "Did you guess that there are a couple of thousand lines of such text in the model?!"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6fabe151-c01b-476d-911e-e801f8c0ee64",
   "metadata": {},
   "source": [
    "|--- total_area <= 60.75\n",
    "|   |--- total_area <= 46.36\n",
    "|   |   |--- cityCenters_nearest <= 7959.50\n",
    "|   |   |   |--- kitchen_area <= 8.10\n",
    "|   |   |   |   |--- living_area <= 21.45\n",
    "|   |   |   |   |   |--- living_area <= 12.50\n",
    "|   |   |   |   |   |   |--- kitchen_area <= 7.50\n",
    "|   |   |   |   |   |   |   |--- class: 0.0\n",
    "|   |   |   |   |   |   |--- kitchen_area >  7.50\n",
    "|   |   |   |   |   |   |   |--- class: 1.0\n",
    "|   |   |   |   |   |--- living_area >  12.50\n",
    "|   |   |   |   |   |   |--- total_area <= 33.75"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e98576-d6a9-4ea6-bfec-8258964aac5e",
   "metadata": {},
   "source": [
    "In Python it would look like this:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3c8084a0-272d-46cb-9a33-275f517156fe",
   "metadata": {},
   "source": [
    "if features['total_area'] <= 60.75:\n",
    "    if features['total_area'] <= 46.36:\n",
    "        answer = 0\n",
    "    else:\n",
    "        if features['ceiling_height'] <= 2.69:\n",
    "            answer = 0\n",
    "        else:\n",
    "            answer = 1\n",
    "else:\n",
    "    answer = 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c939f60-7915-480a-bda5-db2ed523e2e0",
   "metadata": {},
   "source": [
    "What strange conditions! But the computer has no purpose to output beautiful numbers.\n",
    "\n",
    "The ability to look inside the model and understand how a problem is solved can be critical when it comes to people. For example, in the diagnosis of diseases or the analysis of questionnaires to eliminate discrimination in employment. But for business tasks, it is not necessary to make the model “transparent”. The main thing is that it works."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9cf97f-70ef-4cea-bd95-ad75e1aa8af1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Randomness in learning algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcdeea3-dc48-4f9b-a85f-eabc04a3868e",
   "metadata": {},
   "source": [
    "When training a decision tree, each time a new model is obtained."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0959d03-3067-43a7-8132-4d5868b08d60",
   "metadata": {},
   "source": [
    "Randomness is added to many machine learning algorithms to help models notice patterns in data. Let's say you're learning Python.\n",
    "We made 20 cards with new methods and regularly review them. A friend advised me to mix them every time, so the material is absorbed better. By shuffling the cards, you add randomness to the learning algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30e9a7b-522d-40e6-bf6d-8fb17e2614fb",
   "metadata": {},
   "source": [
    "A computer does not create truly random numbers. It connects pseudo-random number generators that produce sequences that look like random ones. For example, the following number cannot be guessed.\n",
    "\n",
    "Random numbers are not so simple: they are unpredictable. Today you trained an artificial intelligence that will flood humanity with spam, and tomorrow it cannot distinguish a cat from a dog."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5598239-1aed-4c63-aa61-df54b87d7d26",
   "metadata": {},
   "source": [
    "Pseudo-random number generators can be configured to consistently produce the same results. The numbers are random, but the same every time, how come? In fact, they just look random.\n",
    "\n",
    "It's the same with learning Python.\n",
    "\n",
    "The translation cards were so successful that you decided to teach others from them. Free of charge. But before that, they prepared and wrote down a different order of cards for each day. In the same sequence, lay them out in front of the students. So you know which card will be the eighth in a row, for example, on Friday. This will not harm the educational process: for the student, the order will still look random."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef97746c-4fec-4409-bf84-d59094790c8b",
   "metadata": {},
   "source": [
    "<img src=\"./pict/3.jpg\"  \n",
    "  width=\"800\" />"
   ]
  },
  {
   "cell_type": "raw",
   "id": "06af46cd-cdef-476f-968a-9a8e088c3e2d",
   "metadata": {},
   "source": [
    "token 06681945a793c575f461d9b47efb67f1725e4f2741dd4237"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5081a8d-cba4-4321-86b3-a43fc7a16883",
   "metadata": {},
   "source": [
    "Fixing pseudo-randomness for the learning algorithm is very simple: when creating it, you need to specify the random_state parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5a4c5b-baff-40d4-a10f-5c00f6d73174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# указываем случайное состояние (число)\n",
    "model = DecisionTreeClassifier(random_state=12345)\n",
    "\n",
    "# обучаем модель как раньше\n",
    "model.fit(features, target) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c79f65-a196-4655-bfaa-fe56bb83ee2b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d05583-9dfb-4c65-857b-6a2c1c000533",
   "metadata": {},
   "source": [
    "They caught the model and took her to the exam. But how to test her knowledge? We need a new dataset with known answers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e895a63f-c926-4b45-802e-52bbe841a7a9",
   "metadata": {},
   "source": [
    "To know for sure that the model did not memorize the answers, let's take a new dataset - a test data set, or a test sample. Let's name the data file `test_data.csv`. Let's check how the model copes with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e1354d-ce04-47cd-8735-546741c265f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('./data/test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a21675-4a97-48af-8ec5-ae78842d10e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.loc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82989bf9-aa01-4bc4-80a5-ac54cda19111",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.loc[test_df['last_price'] > 1159000, 'price_class'] = 1\n",
    "test_df.loc[test_df['last_price'] <= 1159000, 'price_class'] = 0\n",
    "test_features = test_df.drop(['last_price', 'price_class'], axis=1)\n",
    "test_target = test_df['price_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366cfec9-2bbb-4251-ad48-14026c2e6f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(random_state=12345)\n",
    " \n",
    "model.fit(features, target)\n",
    "test_predictions = model.predict(test_features)\n",
    "\n",
    "print('Предсказания:     ',test_predictions)\n",
    "print(\"Правильные ответы:\", test_target.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233450fa-ef7f-4ddc-9f76-76d8bd431b69",
   "metadata": {},
   "source": [
    "Let's write an error_count() function that:\n",
    "- Accepts correct answers and model predictions as input.\n",
    "- Compares them in a for loop.\n",
    "- Returns the number of discrepancies between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9587d99-4034-4a58-893b-1afd0eb11dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_count(answers, predictions):\n",
    "    i = 0\n",
    "    for n,m in zip(answers, predictions):\n",
    "        if n != m:\n",
    "            i += 1\n",
    "    return i\n",
    "\n",
    "print(\"Ошибок:\", error_count(test_target.values, test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51987b5-8f09-41c7-9ad7-cffe0f50d3b1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Proportion of correct answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101fb411-00e1-4fd6-a144-5e72a4c1a6ed",
   "metadata": {},
   "source": [
    "The ratio of the number of correct answers to the size of the test sample is called \"accuracy\". The formula looks like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba42c76-98a4-449a-8350-b4bf53d7d9fa",
   "metadata": {},
   "source": [
    "<font size=\"5\">  \n",
    "    accuracy = number of correct answers / number of questions\n",
    "</font>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0652ede7-5611-4b8d-83d7-1543b3b19de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(answers, predictions):\n",
    "    i = 0\n",
    "    for n,m in zip(answers, predictions):\n",
    "        if n == m:\n",
    "            i += 1\n",
    "    return round(i / len(answers),3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e96abb-60f3-46b4-b236-af1d48f7686c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\", accuracy(test_target, test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8bbbc9-0134-4940-95a8-24e7127c2189",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Quality metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a2115e-5fe3-4f8b-a092-ba9f6ebb2c6e",
   "metadata": {},
   "source": [
    "Is it possible to distinguish a good model from a bad one? How to evaluate the quality of a model? What metric to choose?\n",
    "\n",
    "\n",
    "Quality metrics evaluate the quality of work and are expressed in numerical form. You are already familiar with one quality metric - accuracy.\n",
    "\n",
    "There are others, for example:\n",
    "- `precision` shows what proportion of objects marked as expensive by the model are really expensive (answer 1).\n",
    "- `recall` reveals what part of expensive objects the model has selected.\n",
    "\n",
    "Quality metrics are closely related to the original classification problem.\n",
    "\n",
    "Why did we choose accuracy when determining prices for apartments? Every wrong prediction is a wrong clue and a potential missed opportunity for the seller. And vice versa: the higher the classification accuracy, the more profit the product will bring."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf3d671-9b15-47cb-866d-bbdc57bc58e9",
   "metadata": {},
   "source": [
    "Yes, the higher the quality of the model, the better. But its implementation must be justified.\n",
    "\n",
    "Obvious limits: `accuracy` cannot be less than zero (all answers are wrong) and greater than one (all answers are correct).\n",
    "\n",
    "Set the `accuracy` metric to 0.4, for example. The quality of the model will be high or not?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507ce5df-cbdd-48e0-8b3e-e3ba0ae63f13",
   "metadata": {},
   "source": [
    "<img src=\"./pict/4.jpg\"  \n",
    "  width=\"800\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6baeab51-7577-4c71-953b-caa3bac39112",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Quality metrics in sklearn library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f809fac-ad77-45fc-a3f7-ace8bfcd11d5",
   "metadata": {},
   "source": [
    "You no longer have to calculate accuracy using a formula. `sklearn` has many functions for calculating metrics.\n",
    "\n",
    "In the `sklearn` library, the metrics are in the `sklearn.metrics` module. The accuracy is calculated by the `accuracy_score()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e082e0-057a-43ed-bb84-b32d49ffd3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d8bc73-bdbd-4ec9-ac80-07ab6df9c96a",
   "metadata": {},
   "source": [
    "The function takes two arguments as input:\n",
    "- right answers\n",
    "- model predictions.\n",
    "\n",
    "It returns the value of accuracy. `accuracy = accuracy_score(target, predictions)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a485f468-96db-4645-86ce-ddc1e0d89aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_target, test_predictions) \n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fd522f-f866-4d6e-a25c-3cb66d5a5046",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = model.predict(features)\n",
    "test_predictions = model.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45be288b-5629-47bb-86d4-0175904ae322",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy\")\n",
    "print(\"Training set:\", accuracy_score(target, train_predictions))\n",
    "print(\"Test set:\", accuracy_score(test_target, test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463eaf3f-140c-4f28-89a5-396e31e945b0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Overfitting and underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb9c511-0ef2-40c8-936c-b3443ac42387",
   "metadata": {},
   "source": [
    "Did you find that the accuracy on the test sample of the model is lower than on the training one? This happens a lot in machine learning. Why?\n",
    "\n",
    "Did the model explain the examples from the training data well, but got confused in the test set and could not answer correctly? You've run into a problem with `overfitting`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b2763c-953f-4b32-8488-64dc3fcd2383",
   "metadata": {},
   "source": [
    "Did you find that the accuracy on the test sample of the model is lower than on the training one? This happens a lot in machine learning. Why?\n",
    "\n",
    "Did the model explain the examples from the training data well, but got confused in the test set and could not answer correctly? You've run into a problem with `overfitting`.\n",
    "\n",
    "\n",
    "The opposite effect is `underfitting`. It occurs when the quality on the training and test samples is approximately the same, and low. Eh, it was not possible before the exam not only to memorize the answers, but in general to finish reading the tickets. Familiar story?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14200f44-4858-4a1c-b2c3-25f4596fed2a",
   "metadata": {},
   "source": [
    "`It is not always possible to avoid overfitting or underfitting. When you get rid of the first, the risk of the second effect increases, and vice versa.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5664f8-ca8a-4086-a65a-93834e174689",
   "metadata": {},
   "source": [
    "Look at an example of setting up a learning algorithm. How does it affect the balance between overfitting and underfitting?\n",
    "\n",
    "Tree depth (tree height) is the maximum number of conditions from the \"top\" to the final answer. Counted by the number of hops between nodes. (depth 3 is shown in the figure below)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23ef292-f6b7-4409-97be-ceb5b4022fab",
   "metadata": {},
   "source": [
    "<img src=\"./pict/5.png\"  \n",
    "  width=\"500\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d60387-883a-4a3f-b1ca-b03ef67fdb07",
   "metadata": {},
   "source": [
    "The depth of the tree in `sklearn` is set by the `max_depth` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2569ab26-2bc9-43b4-a39c-6a5275dcc780",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = None\n",
    "best_result = 0\n",
    "\n",
    "for depth in range(1, 12):\n",
    "    model = DecisionTreeClassifier(random_state=12345, max_depth=depth) \n",
    "    model.fit(features, target)\n",
    "    \n",
    "    predictions = model.predict(features) \n",
    "    \n",
    "    result = accuracy_score(target, predictions) \n",
    "    \n",
    "    if result > best_result:\n",
    "        best_model = model\n",
    "        best_result = result\n",
    "        \n",
    "print(\"Accuracy лучшей модели:\", best_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3241ae3e-a6c3-48ad-b5ab-72a093dd0f8a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cf41f7-d715-4f0c-9b82-1836d48abb62",
   "metadata": {},
   "source": [
    "Imagine: you are preparing for an exam on tests from previous years. Don't rush to solve everything at once. Postpone part of the tasks, so that later you can check how well you understand the topic.\n",
    "\n",
    "So it is in machine learning. To make the quality assessment more reliable, you need to prepare a new sample - \"validation\", or test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b87fa7-713f-4d15-816d-5ba93c7ccefa",
   "metadata": {},
   "source": [
    "1) The original dataset is available, but the test set is hidden. Then it is recommended to allocate 75% of the data for training, and 25% for validation. Ratio 3:1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643fd2e1-6dd2-4c79-9ebf-1fbf6c50030d",
   "metadata": {},
   "source": [
    "<img src=\"./pict/6.png\"  \n",
    "  width=\"700\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03b80b9-3b80-447d-9e4a-336c6528b25e",
   "metadata": {},
   "source": [
    "2) There is no hidden test sample. This means that the data needs to be divided into three parts: training, validation and test. The sizes of the test and validation sets are usually equal. The initial data is divided in the ratio 3:1:1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabb0993-742f-4167-8c11-cba4d8a77e5d",
   "metadata": {},
   "source": [
    "<img src=\"./pict/7.png\"  \n",
    "  width=\"700\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae82cb56-84cc-403c-b250-0c10d324228e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Divide by two samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274d7869-29fd-43b7-b765-c0a22e7e6fbb",
   "metadata": {},
   "source": [
    "The validation sample is 25% of the original data. How to extract it?\n",
    "\n",
    "`sklearn` provides the `train_test_split` function for this. It splits any dataset into training and test sets.\n",
    "\n",
    "But we will use this function to get the validation and training sets.\n",
    "Import `train_test_split` from `sklearn.model_selection` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6bc7f4-094f-4777-a745-be4b7873a01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1db627c-3155-43e9-a604-ba9d7fd39457",
   "metadata": {},
   "source": [
    "Before splitting the data set, you need to specify two parameters:\n",
    "    \n",
    "- The name of the set whose data is being shared;\n",
    "- The size of the validation set (test_size). It is expressed in fractions - from 0 to 1. In our example, `test_size=0.25`, since we are working with 25% of the original data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed7708b-83f6-4d42-869e-6de0e09cd8fa",
   "metadata": {},
   "source": [
    "The `train_test_split()` function returns two new datasets −"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71655ba1-d6b2-4d55-9d35-87692d5a2a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_valid = train_test_split(df, test_size=0.25, random_state=12345) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213bb6f0-2443-4602-8050-2c3a4d2475ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = df_train.drop(['last_price', 'price_class'], axis=1)\n",
    "target_train = df_train['price_class']\n",
    "\n",
    "features_valid = df_valid.drop(['last_price', 'price_class'], axis=1)\n",
    "target_valid = df_valid['price_class'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c52901f-e99c-4946-80a6-d3e5249ab35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features_train.shape)\n",
    "print(target_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5e1074-7a47-44ec-8ba3-8744e2e5b86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features_valid.shape)\n",
    "print(target_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7697fdf-be71-4b09-af5f-5aed4133f9d9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3392020b-5547-4a42-b773-fad1051cae84",
   "metadata": {},
   "source": [
    "`Hyperparameters` are settings for learning algorithms. Unlike parameters, they are set before the learning process.\n",
    "\n",
    "In a decision tree, for example, this is the maximum depth or the choice of a criterion - Gini or entropy. Hyperparameters help improve the model. You can change them before the start of training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a3a2a7-4881-46a5-94af-cc30e4ca3a49",
   "metadata": {},
   "source": [
    "Take another look at the already familiar code:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c89a4161-618a-4c71-bb28-ad5280810508",
   "metadata": {},
   "source": [
    "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
    "                        max_features=None, max_leaf_nodes=None,\n",
    "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                        min_samples_leaf=1, min_samples_split=2,\n",
    "                        min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "                        splitter='best') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acef2bbd-1229-4437-b631-91b65146c4cd",
   "metadata": {},
   "source": [
    "- `criterion='gini'` is a Gini criterion that shows a measure of similarity between two sets of data. While learning, the tree at each node (at each fork) of the possible questions asks the best one. Now it selects the question for which the Gini test shows that the data assigned to the left branch is the least similar to those on the right.\n",
    "- `min_samples_split` - this hyperparameter prohibits creating nodes that contain too few training sample objects.\n",
    "- `min_samples_leaf` are bottom nodes with answers. And the hyperparameter does not allow you to create a sheet in which there are too few objects in the training sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd52f1d-7db7-495f-8286-8fa9b51523d6",
   "metadata": {},
   "source": [
    "## Changing hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524daca3-2581-4cdc-88a1-093a8f118eec",
   "metadata": {},
   "source": [
    "Let's tune the hyperparameters of our decision tree.\n",
    "\n",
    "The most important decision tree hyperparameter is `max_depth`. It is he who determines what we will end up with - a stump with one question or a maple tree with a branched crown."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8566a8-a75d-44be-9014-f1cd5e95eac5",
   "metadata": {},
   "source": [
    "<img src=\"./pict/8.jpg\"  \n",
    "  width=\"500\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564f24c3-60d8-46bb-9c18-d61851f9978a",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_array = []\n",
    "best_model = None\n",
    "best_result = 0\n",
    "\n",
    "for depth in range(1, 24):\n",
    "    model = DecisionTreeClassifier(random_state=12345, max_depth=depth)\n",
    "    model.fit(features_train, target_train)\n",
    "    \n",
    "    predictions_valid = model.predict(features_valid)\n",
    "    result = accuracy_score(target_valid, predictions_valid)\n",
    "\n",
    "    if result > best_result:\n",
    "        best_result = result\n",
    "        \n",
    "    print('max_depth =', depth,': ', end='')\n",
    "    print(result)\n",
    "\n",
    "    accuracy_array.append([depth, result])\n",
    "    \n",
    "df_ac = pd.DataFrame(accuracy_array, columns=['depth', 'accuracy'])\n",
    "print('')\n",
    "print('best result :', best_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c49dc93-5193-4110-938d-5248188718e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = sns.lineplot(data=df_ac, x=\"depth\", y=\"accuracy\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da83f227-4a01-4677-a7c5-c25f893d4ac2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# New models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e0ea90-c3e3-40a8-b582-70fd0b485c14",
   "metadata": {
    "tags": []
   },
   "source": [
    "## random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ba2493-4a2e-4b3e-99e5-494b22e263fd",
   "metadata": {},
   "source": [
    "You have changed the hyperparameters of the model. But the result is still not satisfactory. One tree is clearly not enough, you need a whole forest!\n",
    "\n",
    "Let's try a new classification algorithm - random forest. The algorithm trains a large number of independent trees, and then makes a decision based on voting. Random forest helps to improve the prediction result and avoid overfitting.\n",
    "\n",
    "Have you ever wondered why there are always several people on the jury? So that the final grade of the speaker is average. So personal preferences and mistakes are smoothed out. Random forest works the same way.\n",
    "\n",
    "\n",
    "How to train him? In the `sklearn` library, the `RandomForestClassifier` random forest algorithm resides in the `sklearn.ensemble` module. Let's import it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333dcb6c-6b8d-4987-b734-97d69f884abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763f4724-3ba2-42c4-a54a-c9531374e7cc",
   "metadata": {},
   "source": [
    "To control the number of trees in the forest, we write the `n_estimators` hyperparameter. The more trees, the longer the model will learn, but the result will be better (and vice versa). Let's take the value of `n_estimators` equal to 3 for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ea9784-0b49-4714-a7e1-4782b9c126f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(random_state=12345, n_estimators=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57751735-3cff-47c6-9eb8-fd1fd017ff36",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(features_train, target_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7b001c-2707-443b-8b0e-2e2cfe9651d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.score(features_valid, target_valid) \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fed99fa-3246-40d0-bdf2-8b974eb59153",
   "metadata": {},
   "source": [
    "Let's test the hyperparameters by increasing the number of trees to 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729529de-30ab-4d16-a616-bff5ef038620",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c954e79-f22f-4583-8237-cec7e536f0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = None\n",
    "best_result = 0\n",
    "\n",
    "for est in tqdm(range(1, 18)):\n",
    "    for depth in range(1, 18): \n",
    "        model = RandomForestClassifier(random_state=12345, n_estimators=est, max_depth=depth) \n",
    "        model.fit(features_train, target_train) \n",
    "        result = model.score(features_valid, target_valid) \n",
    "        if result > best_result:\n",
    "            best_depth = depth\n",
    "            best_est = est\n",
    "            best_model = model\n",
    "            best_result = result\n",
    "print(\"Accuracy наилучшей модели на валидационной выборке:\", best_result)\n",
    "\n",
    "print('')\n",
    "print('best_depth =', best_depth)\n",
    "print('best_est =', best_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba24cf3-eb20-4fa9-9525-697d8336f7df",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4b972f-65f3-4ad6-945c-48700aae0a0a",
   "metadata": {},
   "source": [
    "Algorithms are not limited to trees. There are other ways to classify.\n",
    "\n",
    "If you make the `n_estimators` hyperparameter larger, the model will grow and learn slowly. This is bad. There are few trees and the results are not better - also unsuccessful. How long can you be dependent on trees?\n",
    "\n",
    "Let's try another algorithm - `logistic regression`.\n",
    "\n",
    "Even if the name `mimics` a regression problem, it is still a classification algorithm.\n",
    "\n",
    "To predict housing class, logistic regression:\n",
    "- First, it considers which class the object is close to. For example, with this formula:\n",
    "- Depending on the answer, selects the required class: if the result of the calculation is positive, then - 1 (high prices); negative - 0 (low prices)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1c7ae2-1d6c-4029-a67e-07a512d7fa97",
   "metadata": {},
   "source": [
    "<font size=\"5\">\n",
    "    proximity to class = 10 * area - distance to center\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc48a07-84c9-4181-be5a-26a86e612469",
   "metadata": {},
   "source": [
    "The area increases the cost, and the distance to the center reduces it. Moreover, each square meter of area is 10 times more important than one meter to the center.\n",
    "\n",
    "We only considered area and distance. But in order to get proximity to the class, all features are placed in the black box."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9966daf8-e5db-4f8c-abe0-193c065ae2f2",
   "metadata": {},
   "source": [
    "The LogisticRegression model lies in the `sklearn.linear_model` module of the `sklearn` library. Import it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201f160d-86ea-405d-9a10-188faffd74ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8705266b-49a7-401a-8cac-3b77f731640b",
   "metadata": {},
   "source": [
    "solver `'lbfgs'` is one of the most common. It is suitable for most tasks. The `max_iter` hyperparameter sets the maximum number of training iterations, the default value of this parameter is 100, but in some cases more iterations will be needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649a5ac6-513a-4d66-a317-25dde1d4f630",
   "metadata": {},
   "source": [
    "before changing the `solver` parameter, familiarize yourself with what tasks they are suitable for, you can familiarize yourself with <a rel=\"stylesheet\" type=\"text/css\" href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\">here</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9858371-b004-47b4-a086-42064e417b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#liblinear\n",
    "#lbfgs\n",
    "iterat = 1000\n",
    "model = LogisticRegression(solver='liblinear', max_iter=iterat) \n",
    "model.fit(features_train, target_train) \n",
    "\n",
    "result = model.score(features_valid, target_valid)\n",
    "    \n",
    "print('result :', result)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac00b965-569f-497a-a799-ce07e4d9f34d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Compare models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a20caa5-a1a8-48d9-8e74-23a0bdcf4b32",
   "metadata": {},
   "source": [
    "It is not necessary to work with three models at the same time. Each has its own merits and demerits. Let's evaluate the models in terms of quality (accuracy) and speed of work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44283acd-a21f-46b2-b2c3-ad20b5f0943a",
   "metadata": {},
   "source": [
    "- Decisive tree quality Medium, speed High\n",
    "- Random forest quality High, speed Low\n",
    "- Logic quality Low, speed High"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8df739-8892-415a-a94d-9ce2f1f6c1da",
   "metadata": {},
   "source": [
    "the necessary parameters are often chosen based on business priorities, not always a slight improvement in the quality of the model will be a priority for the speed of work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a116f4-0eb2-41f1-b11a-17b0c32c5cf7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733557fe-7e88-468b-84d5-5725d67231be",
   "metadata": {},
   "source": [
    "How is classification different from regression?\n",
    "\n",
    "The target attribute (response) can be categorical and quantitative. If it is categorical, then the classification problem is solved; if quantitative - regressions.\n",
    "\n",
    "The price of an apartment is a quantitative target sign. So, we need to solve the regression problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6c2b61-d6e2-45c0-9301-7f4d18096b92",
   "metadata": {
    "tags": []
   },
   "source": [
    "## RMS error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff91317f-e6e6-4395-8e88-d227551c4105",
   "metadata": {},
   "source": [
    "What would be the \"correct answer\" in your problem? Complete, down to the last penny, the price match of the apartment? If absolute accuracy is not important in the task, the accuracy metric is not suitable.\n",
    "\n",
    "The most common quality metric in a regression problem is the mean square error, MSE (Mean Squared Error).\n",
    "\n",
    "To get the MSE, the error of each object is first calculated:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8f5ae9-ada9-4e71-bedc-bd607c0fd0e7",
   "metadata": {},
   "source": [
    "<font size=\"5\">  \n",
    "    object error = model predictions - correct answer\n",
    "</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0881a246-2cdd-4c2e-a640-4800ea0022b2",
   "metadata": {},
   "source": [
    "MSE is calculated according to the scheme:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47f4562-6149-416f-a1c7-f2eb5e6d54df",
   "metadata": {},
   "source": [
    "<font size=\"5\">  \n",
    "    MSE = sum of squared object errors / number of object\n",
    "</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c218a493-44b8-4505-ba37-6d73b366d2fc",
   "metadata": {},
   "source": [
    "What do calculations mean?\n",
    "\n",
    "1) Object error shows how much the correct answer differs from the prediction. If the error is much greater than zero, the model has overestimated the flat; less - underestimated.\n",
    "2) Squaring removes the difference between overestimation and underestimation. Without this step, it makes no sense to sum up the errors: the positive ones will compensate for the negative ones.\n",
    "3) Averaging is needed to get data for all objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9556c6fd-633b-484a-b62b-35dc6a46bf9c",
   "metadata": {},
   "source": [
    "<img src=\"./pict/9.png\"  \n",
    "  width=\"700\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c8b7c5-8ab1-4f33-96fc-752fd5af8f4e",
   "metadata": {},
   "source": [
    "We have achieved the highest accuracy in the past. The value of MSE, on the contrary, should be as small as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e100f8d2-7f67-4019-85cf-678631fbb2b4",
   "metadata": {},
   "source": [
    "The MSE calculation function is also available in sklearn. Import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524a316c-1399-412a-b09b-28f63d4680af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5686e230-4f60-4d3a-af6b-ee600c8d7331",
   "metadata": {
    "tags": []
   },
   "source": [
    "## MSE interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872fdef8-3470-4f4c-8578-93925dbcbd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/train_data.csv')\n",
    "\n",
    "df_train, df_valid = train_test_split(df, test_size=0.25, random_state=12345) \n",
    "\n",
    "df_valid=df_valid.reset_index(drop=True)\n",
    "\n",
    "features_train = df_train.drop(['last_price'], axis=1)\n",
    "target_train = df_train['last_price']\n",
    "\n",
    "features_valid = df_valid.drop(['last_price'], axis=1)\n",
    "target_valid = df_valid['last_price'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ea7c41-fc18-400a-961e-b84950274eaa",
   "metadata": {},
   "source": [
    "To assess the adequacy of the model in classification tasks, it is necessary to compare it with a random one.\n",
    "\n",
    "Responding to all objects with the same number is a simple way of regression prediction. So that it does not differ much from the truth, we will take the average value of the price of an apartment as such a number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f5c44e-ff83-4c0f-9ef1-f5d8f1b795ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.Series(target_train.mean(), index=target_train.index)\n",
    "mse = mean_squared_error(target_train, predictions)\n",
    "\n",
    "print(\"MSE:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942c0c97-7330-4876-beea-11ba37676965",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(target_train.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21295e6e-50d8-4485-9fb5-754a22eb6903",
   "metadata": {},
   "source": [
    "\"Square hryvnia\" is useless. In order for the metric to show just hryvnias, let's take the root of MSE. This is the RMSE (root mean squared error) value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd5c902-7646-4944-8e00-57c758e12f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = mse ** 0.5\n",
    "print(\"RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c0eb8a-3dbc-438e-aa06-07c028200e95",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Decision tree in regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b762f91-99d0-4e38-bda8-c2fa924f7a7a",
   "metadata": {},
   "source": [
    "The decision tree is suitable not only for classification problems, but also for regression.\n",
    "\n",
    "The tree in the regression problem is trained in the same way, only it predicts not a class, but a number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ca1e9b-608c-4f6f-90d4-a952e27be423",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85d51fa-1203-4f6d-8bb2-f3a760c7109c",
   "metadata": {},
   "source": [
    "<img src=\"./pict/10.jpg\"  \n",
    "  width=\"800\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4878bb1-8562-4603-bec5-740a050dc63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = None\n",
    "best_result = 9999999999999999999999\n",
    "for depth in range(1, 24):\n",
    "    model = DecisionTreeRegressor(random_state=12345, max_depth=depth)\n",
    "    model.fit(features_train, target_train)\n",
    "    predictions_valid = model.predict(features_valid)\n",
    "    \n",
    "    result = mean_squared_error(target_valid, predictions_valid)**0.5 \n",
    "    if result < best_result:\n",
    "        best_model = model\n",
    "        best_result = result/1000\n",
    "\n",
    "print(\"RMSE best model on the validation set:\", best_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34513b59-a70e-4659-a10c-272c0013ba0b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Random forest in regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd995c38-b9e7-4e48-bed3-565517bbbd93",
   "metadata": {},
   "source": [
    "Where there is one tree, there is a forest. Let's figure out how to train a random forest model in regression.\n",
    "\n",
    "The random forest for regression does not change much. It trains many independent trees and then makes a decision by averaging their responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be21e011-ada0-4edb-b77a-b8474ecf71c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3042c3-004e-4406-80d1-96ad37c09e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = None\n",
    "best_result = 9999999999999999999999\n",
    "\n",
    "for est in tqdm(range(10, 51, 10)):\n",
    "    for depth in range (1, 11):\n",
    "        model = RandomForestRegressor(random_state=12345, n_estimators=est, max_depth=depth)\n",
    "        model.fit(features_train, target_train) \n",
    "        predictions_valid = model.predict(features_valid) \n",
    "        result = mean_squared_error(target_valid, predictions_valid)**0.5 \n",
    "        if result < best_result:\n",
    "            best_model = model\n",
    "            best_result = result/1000\n",
    "\n",
    "print(\"RMSE best model on the validation set:\", best_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0498e7d-14a0-4c7a-92b2-1b853616c4dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86232f8-9fa1-402e-a0d0-16215292f171",
   "metadata": {},
   "source": [
    "What algorithm will replace logistic regression? Linear regression!\n",
    "\n",
    "Linear regression is similar to logistic. The name comes from linear algebra.\n",
    "\n",
    "Due to the small number of parameters, linear regression is less prone to overfitting than, for example, decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e678c7-97fc-44a2-abe8-91152c7f1216",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ad67fd-b246-47a1-b435-076b07809af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(features_train, target_train) \n",
    "predictions_valid = model.predict(features_valid) \n",
    "\n",
    "result = mean_squared_error(target_valid, predictions_valid)**0.5 /1000\n",
    "print(\"RMSE best model on the validation set:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c10e1b9-ed61-4f6f-aade-cf2f61d0bb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid = target_valid.to_frame()  # from series to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2befecf-c8ec-45cb-b7fb-573d905b9b58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed2b2be-770a-4536-804a-58df97a85f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid = target_valid.to_frame()  # from series to dataframe\n",
    "\n",
    "\n",
    "\n",
    "df_target = pd.DataFrame(predictions_valid, columns=['target'])  # predictions_valid - numpy array, create dataframe\n",
    "\n",
    "\n",
    "df_valid['predict'] = df_target  # join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63933db4-8378-47ad-afea-f1367451a3f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_valid = df_valid.sort_values('last_price').reset_index(drop=True).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ef7dee-c253-43ad-942b-f0933c98b178",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_plot(df, start=0, end=999999999):\n",
    "    df_plot = df.loc[(df['index']>=start) & (df['index']<=end)]\n",
    "    df_plot.loc[:, 'last_price'] = df_plot['last_price']/1000\n",
    "    df_plot.loc[:, 'predict'] = df_plot['predict']/1000\n",
    "    \n",
    "    ax = df_plot.plot(x = 'index',\n",
    "                 y = 'last_price',\n",
    "                 kind = 'scatter',                    \n",
    "                 style = '-o',                          \n",
    "                 alpha = 0.1,       \n",
    "                 legend = True,          \n",
    "                 label = 'target',                                  \n",
    "                 figsize = (8, 4.5),                   \n",
    "                 grid = True)\n",
    "    (df_plot.plot(ax = ax,\n",
    "                   y = 'predict',\n",
    "                   style = '-r',\n",
    "                   alpha = 0.6, \n",
    "                   legend = True,          \n",
    "                   label = 'predict',    \n",
    "                   grid = True              \n",
    "                  ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082d3b94-909f-4811-8ab6-bfe211a80aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_plot(df_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7932d419-87a9-4754-a8ba-2b6adda38431",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_plot(df_valid, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1299c1b8-a844-4614-9856-cb5c4c9beb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid.loc[df_valid['predict']<0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed824ec8-86ad-4bcd-8ca1-0317cfcd92ca",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ba65ea-733d-4fed-aae6-77bfa870f430",
   "metadata": {},
   "source": [
    "<img src=\"./pict/25.jpg\"  \n",
    "  width=\"800\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6ded84-09f4-4b14-8fce-fa3ec9bcbd87",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h2>Linear Regression</h2>\n",
    "<div class='alert alert-success'>\n",
    "<b>Good</b>\n",
    "    \n",
    "- Simple to implement and efficient train\n",
    "- Overfiting can br reduced by regularization\n",
    "- Performs well when the dataset is linearly separable     \n",
    "</div>\n",
    "\n",
    "<div class='alert alert-danger'>\n",
    "<b>Bad</b>\n",
    "    \n",
    "- Assumes thet data is independent which is rare in real life\n",
    "- Prone to noise and overfiting\n",
    "- Sesitive to outliers\n",
    "</div>\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08e2560-8b3d-4058-8aaa-87fcb42f1d1d",
   "metadata": {},
   "source": [
    "<img src=\"./pict/line.png\"  \n",
    "  width=\"600\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4480ce9d-4599-4cc5-8375-e982b46ff78c",
   "metadata": {},
   "source": [
    "<h2>Logistic Regression</h2>\n",
    "<div class='alert alert-success'>\n",
    "<b>Good</b>\n",
    "    \n",
    "- Less prone to over-fiting but it can overfit in hight dimensional dataset\n",
    "- Efficient when the dataset has features that are linearly separable\n",
    "- Easy to implement and efficient to train\n",
    "</div>\n",
    "\n",
    "<div class='alert alert-danger'>\n",
    "<b>Bad</b>\n",
    "    \n",
    "- Should not be used when the number of observations are lesser than the number of features\n",
    "- Assumption of linearity which is rare in practise\n",
    "- Can only be used to predict discrete functions\n",
    "</div>\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa65e87f-3fd7-4217-ba33-dda600aa57d8",
   "metadata": {},
   "source": [
    "<img src=\"./pict/logic.png\"  \n",
    "  width=\"600\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384e431c-424e-4aeb-9120-3c9adbc602a2",
   "metadata": {},
   "source": [
    "<h2>Decision Tree</h2>\n",
    "<div class='alert alert-success'>\n",
    "<b>Good</b>\n",
    "    \n",
    "- Can solve non-linear problems\n",
    "- Can work on hight-dimensional data with wxcellent accuracy\n",
    "- Easy to visualize and explain\n",
    "</div>\n",
    "\n",
    "<div class='alert alert-danger'>\n",
    "<b>Bad</b>\n",
    "    \n",
    "- Overfiting. Might be resolved by random forest\n",
    "- A small change in the data can lead to a large change in the structure of the optimal decision tree\n",
    "- Calculations can get very complex\n",
    "</div>\n",
    "\n",
    "https://scikit-learn.org/stable/modules/tree.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcef37c-1f31-4fb3-ab3c-e9af9e578a5a",
   "metadata": {},
   "source": [
    "<img src=\"./pict/tree.png\"  \n",
    "  width=\"800\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7d640c-3afc-434e-9bcf-675efc873a71",
   "metadata": {},
   "source": [
    "<h2>Support Vector Machine</h2>\n",
    "<div class='alert alert-success'>\n",
    "<b>Good</b>\n",
    "    \n",
    "- Good at hight dimensional data\n",
    "- Can work on small dataset\n",
    "- Can solve non-liner problems\n",
    "</div>\n",
    "\n",
    "<div class='alert alert-danger'>\n",
    "<b>Bad</b>\n",
    "    \n",
    "- Inefficient on large data\n",
    "- Requires picking the right kernal \n",
    "</div>\n",
    "\n",
    "https://scikit-learn.org/stable/modules/svm.html#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96649f36-9d97-4896-87be-8ec9487103e1",
   "metadata": {},
   "source": [
    "<img src=\"./pict/svm.png\"  \n",
    "  width=\"400\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1a4b32-d4bb-404d-97c9-f21e9933b1aa",
   "metadata": {},
   "source": [
    "<h2>Naive Bayes</h2>\n",
    "<div class='alert alert-success'>\n",
    "<b>Good</b>\n",
    "    \n",
    "- Training period is less\n",
    "- Better suited for categorical imputs\n",
    "- Easy to implement\n",
    "</div>\n",
    "\n",
    "<div class='alert alert-danger'>\n",
    "<b>Bad</b>\n",
    "    \n",
    "- Assumes that all features are independent wich is rarely happening is real life \n",
    "- Zero Frequency\n",
    "- Estimations can be wronmg in same cases\n",
    "</div>\n",
    "\n",
    "https://scikit-learn.org/stable/modules/naive_bayes.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cb8f05-c156-44c4-97f4-77af9701403f",
   "metadata": {},
   "source": [
    "<img src=\"./pict/bayes.png\"  \n",
    "  width=\"400\" />"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
